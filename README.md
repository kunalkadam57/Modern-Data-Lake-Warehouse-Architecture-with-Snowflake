# Modern Data Lake & Warehouse Architecture with Snowflake

## ðŸš€ Project Overview

This project demonstrates how to build a modern data lake and data warehouse solution using **Snowflake**, incorporating key data engineering patterns such as:
- External Tables over Parquet and JSON
- Streams and Tasks for CDC and automation
- Snowflake Stages for file ingestion
- Timezone-aware CTAS transformations
- Data warehouse modeling

## ðŸ“‚ Folder Structure

```
snowflake_data_lake_warehouse_project/
â”œâ”€â”€ raw_data/
â”‚   â”œâ”€â”€ sales_data.parquet
â”‚   â””â”€â”€ customer_data.json
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_external_stage.sql
â”‚   â”œâ”€â”€ create_external_table.sql
â”‚   â”œâ”€â”€ parse_json_and_merge.sql
â”‚   â”œâ”€â”€ create_streams_and_tasks.sql
â”‚   â”œâ”€â”€ ctas_transformations.sql
â”‚   â””â”€â”€ warehouse_model.sql
â”œâ”€â”€ diagrams/
â”‚   â””â”€â”€ architecture.png
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## ðŸ§  Key Concepts Covered

- `Snowflake Stages`, `External Tables`, `Streams`, `Tasks`
- Ingestion and transformation of JSON & Parquet
- CDC handling with Streams
- CTAS transformations with timezones
- Dimensional modeling with final fact table

## ðŸ›  Technologies Used

- **Snowflake SQL**
- **Parquet / JSON files**
- **Amazon S3 (can be mocked locally)**
